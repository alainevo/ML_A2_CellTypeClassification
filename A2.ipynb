{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alainevo/cosc2673_a2/blob/main/A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN3vjfhXciFB"
      },
      "source": [
        "## Load and Set up\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FiO6eEOcgXa"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iTlf8cUJkdWD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import os, zipfile\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIWajJfvlSRx"
      },
      "source": [
        "Check if notebook is running in colab to prepare for dataloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGfjw28MG5_l"
      },
      "outputs": [],
      "source": [
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   InColab = True\n",
        "else:\n",
        "   InColab = False\n",
        "   \n",
        "if InColab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4vdNodGlace"
      },
      "source": [
        "**Load data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6yNHpXZP-Jr"
      },
      "outputs": [],
      "source": [
        "if InColab:\n",
        "  if pathlib.Path('/dataset').exists():\n",
        "    !rm -rf /dataset \n",
        "  with zipfile.ZipFile('/content/drive/MyDrive/A2/Image_classification_data.zip','r') as zip_ref:\n",
        "      zip_ref.extractall(\"/dataset\")\n",
        "      data = pd.read_csv('/dataset/data_labels_mainData.csv')\n",
        "      data_extra = pd.read_csv('/dataset/data_labels_extraData.csv')\n",
        "\n",
        "else:\n",
        "  if pathlib.Path('./dataset').exists():\n",
        "    !rm -rf ./dataset \n",
        "  with zipfile.ZipFile('./Image_classification_data.zip','r') as zip_ref:\n",
        "      zip_ref.extractall(\"./dataset\")\n",
        "      data = pd.read_csv('./dataset/data_labels_mainData.csv')\n",
        "      data_extra = pd.read_csv('./dataset/data_labels_extraData.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg17Qh120rMv"
      },
      "source": [
        "Check if the data is loaded properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQZVE-DUUGdj"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTk7bDz1y3zp"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# MOUNT_PATH = '/content/drive/'\n",
        "# PROJECT_DIR = MOUNT_PATH + 'My Drive//'\n",
        "\n",
        "# drive.mount(MOUNT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSznpiWZzF5T"
      },
      "outputs": [],
      "source": [
        "# data = pd.read_csv(PROJECT_DIR + \"data_labels_mainData.csv\")\n",
        "# data_extra = pd.read_csv(PROJECT_DIR + \"data_labels_extraData.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2AkHFMqzU-u"
      },
      "outputs": [],
      "source": [
        "# !unzip -n -qq /content/drive/MyDrive/A2/patch_images.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4thTfw2Pc_MY"
      },
      "source": [
        "# Task I: Cancerous Cell Classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COLt96OXd8i0"
      },
      "source": [
        "## 1. Overview & Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMTYFFYBeHTx"
      },
      "source": [
        "## 2. Exploratory Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMkIOYen5OC5"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2di7ln25QeD"
      },
      "source": [
        "**Observation:**\n",
        "* No missing values\n",
        "* Data type of cellType and isCancerous are correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlNERRIGiXg1"
      },
      "source": [
        "### Identifying Class Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C9Dy7K6oaiN"
      },
      "source": [
        "Plot the graph to show number between cancer patients and non-cancer patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQkD5q4YrbR5"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "count_cancer_data = data.groupby('patientID')['isCancerous'].nunique().reset_index()\n",
        "fig = plt.subplots(figsize=(3, 3))\n",
        "\n",
        "ax = sns.countplot(x ='isCancerous', data = count_cancer_data)\n",
        "ax.set_ylim([0, max(count_cancer_data['patientID']) + 1])\n",
        "ax.set_xticklabels(['Non-Cancer', 'Cancer'])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.title('No. of Cancer Patients vs Non-Cancer Patients')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dZT07TPgGdD"
      },
      "source": [
        "Plot the number of cancerous cell and non-cancerous cell in the main dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_L_Poqiz5U5"
      },
      "outputs": [],
      "source": [
        "fig = plt.subplots(figsize=(3, 3))\n",
        "ax = sns.countplot(x ='isCancerous', data = data)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=0)\n",
        "ax.set_ylim([0, data.shape[0]])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.title('No. of Non-Cancerous Cell vs Cancerous Cell in MainDataset')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o75nzFgW5GFS"
      },
      "source": [
        "As can be seen from the plot above, **the dataset is imbalance** between Cancerous Cell and Non-Cancerous Cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac3cfnx9jKtz"
      },
      "outputs": [],
      "source": [
        "fig = plt.subplots(figsize=(3.7, 3.7))\n",
        "\n",
        "# Count the occurrences of each cell type\n",
        "counts = data['cellTypeName'].value_counts().reset_index()\n",
        "\n",
        "# Rename the columns\n",
        "counts.columns = ['cellTypeName', 'count']\n",
        "\n",
        "# Plot the pie chart\n",
        "plt.pie(counts['count'], labels=counts['cellTypeName'], autopct=lambda x: '{:.0f}\\n({:.1f}%)'.format(x * sum(counts['count']) / 100, x))\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Distribution of Cell Types')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC16DGezeALs"
      },
      "source": [
        "From the pie chart above, we can see that the number of Epithelial cells accounts for the majority with 41.2% compared to other cell types such as inflammatory (25.7%), and fibroblast (19.1%), while others cell type only accounts for 14.0% of the total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnJ7z2plCJ9Q"
      },
      "outputs": [],
      "source": [
        "# Group the dataframe by Cell_Type and isCancerous, then calculate the count of each group\n",
        "counts = data.groupby(['cellTypeName', 'isCancerous']).size().reset_index(name='Count')\n",
        "\n",
        "# Plot the distribution of cell types by isCancerous attribute\n",
        "ax = sns.barplot(data=counts, x='cellTypeName', y='Count', hue='isCancerous')\n",
        "\n",
        "# Add text labels to the bars with the count of each cell type\n",
        "for p in ax.patches:\n",
        "    x = p.get_x() + p.get_width() / 2\n",
        "    y = p.get_height()\n",
        "    ax.annotate(y, (x, y), ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Distribution of Cell Types by isCancerous')\n",
        "\n",
        "# Set the x label\n",
        "plt.xlabel('Cell Type')\n",
        "\n",
        "# Set the y label\n",
        "plt.ylabel('Count')\n",
        "ax.set_ylim([0, 6000])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n76CWfDaDldr"
      },
      "source": [
        "**Observation:**\n",
        "* From the chart above, we can see that all cancerous cells have only one type which is Epithelial.\n",
        "* The number of epithelial cell is also equal to the number of the cancerous cell in the dataset which is both 4079.\n",
        "\n",
        "➡️ All epithelial cells are cancerous cell.\n",
        "\n",
        "💡 From this exploration, we can utilize the extra dataset, which only provides the label for isCancerous, to enhance the cell-type classification model later on Task 2. We can assume that all cancerous cells in the extra dataset belong to the Epithelial cell type.\n",
        "\n",
        "Next, we can check for the extra dataset to have a better understanding before utilizing it for Task 1 (which is classifying a cell is cancerous or not)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puJ2ColqP0o-"
      },
      "source": [
        "**Extra dataset “Data labels extraData.csv” exploration.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_fXa-TyQRkz"
      },
      "outputs": [],
      "source": [
        "fig = plt.subplots(figsize=(3, 3))\n",
        "ax = sns.countplot(x ='isCancerous', data = data_extra)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=0)\n",
        "ax.set_ylim([0, data.shape[0]])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.title('No. of Cancerous Cell vs Non-Cancerous Cell in ExtraDataset')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjI51UQehljm"
      },
      "source": [
        "**Observation:** The extra dataset has a heavy imbalance between the 2 classes than the main dataset.\n",
        "\n",
        "Since the datasets are imbalance we must be careful when choose the proper evaluation metrics later on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftmLeZ2qho2i"
      },
      "source": [
        "### Viewing Image Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP6oP6YUkZCs"
      },
      "source": [
        "1. Distribution of image sizes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvKTV3uRnwh_"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Set the path to the image directory\n",
        "image_dir = '/dataset/patch_images/'\n",
        "\n",
        "# Create a list to store the image sizes\n",
        "image_sizes = []\n",
        "\n",
        "# Iterate through the dataset and get the size of each image\n",
        "for img_name in data['ImageName']:\n",
        "    img_path = os.path.join(image_dir, img_name)\n",
        "    with Image.open(img_path) as img:\n",
        "        image_sizes.append(img.size)\n",
        "\n",
        "# Plot the image size distribution\n",
        "plt.hist(image_sizes, bins=15)\n",
        "plt.xlabel('Image Size')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Image Size Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_4eeL4Kg20S"
      },
      "source": [
        "The image sizes seem to have the same distribution. Therefore, we do not need to resize the images. Now, we can plot some images for checking it in more detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keis0tvzqWrG"
      },
      "source": [
        "2. Plotting some images:\n",
        "\n",
        "We can plot some random images of each cell type to get an overview look of them. Also, we can check for any Mislabeling in our image data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUN4gjJnxC0Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Group the images by cell type\n",
        "groups = data.groupby('cellTypeName')\n",
        "\n",
        "# Select a few images from each group for plotting\n",
        "n_samples = 5\n",
        "for cell_type, group in groups:\n",
        "    sample = group.sample(n=n_samples, replace=True)\n",
        "    sample_images = []\n",
        "    for index, row in sample.iterrows():\n",
        "        filename = row['ImageName']\n",
        "        filepath = '/dataset/patch_images/' + filename\n",
        "        image = Image.open(filepath)\n",
        "        sample_images.append(image)\n",
        "    \n",
        "    # Check if any of the images are empty\n",
        "    if None in sample_images:\n",
        "        print(f\"Warning: Empty images found for cell type {cell_type}\")\n",
        "    \n",
        "    # Plot the sample images\n",
        "    if all(sample_images):\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        for i, image in enumerate(sample_images):\n",
        "            plt.subplot(1, n_samples, i+1)\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')\n",
        "        plt.suptitle(cell_type, fontsize=12)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di8MSeWvcqY7"
      },
      "source": [
        "For further development of this model, we can collaborate with biological experts to detect if there is any Image Mislabeled and relabel it. In this current project, we may skip this part with the assumption that the dataset does not have Mislabeling Data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgcRvbL_tTEX"
      },
      "source": [
        "3. Checking duplicate image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shLSo0SAdYlM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import hashlib\n",
        "# create a dictionary to store the md5 hashes and corresponding file paths\n",
        "md5_dict = {}\n",
        "\n",
        "# create a list to store the filenames of the duplicate images\n",
        "duplicates = []\n",
        "\n",
        "# set the path to the image directory\n",
        "image_dir = '/dataset/patch_images/'\n",
        "\n",
        "# init the variable to count duplicate\n",
        "count = 0\n",
        "\n",
        "# iterate through each image filename in the dataset\n",
        "for filename in data['ImageName']:\n",
        "    # search for the image file in the directory\n",
        "    filepath = os.path.join(image_dir, filename)\n",
        "    if os.path.isfile(filepath):\n",
        "        # open the file in binary mode and read its content\n",
        "        with open(filepath, 'rb') as f:\n",
        "            content = f.read()\n",
        "            # compute the md5 hash of the file content\n",
        "            md5_hash = hashlib.md5(content).hexdigest()\n",
        "            # check if the hash already exists in the dictionary\n",
        "            if md5_hash in md5_dict:\n",
        "                print(f'Duplicate image: {filename}')\n",
        "                print(f'Original file: {md5_dict[md5_hash]}')\n",
        "                count += 1\n",
        "                # add the filename to the list of duplicate images\n",
        "                duplicates.append(filename)\n",
        "                duplicates.append(md5_dict[md5_hash])\n",
        "            else:\n",
        "                md5_dict[md5_hash] = filepath\n",
        "    else:\n",
        "        print(f'File not found: {filename}')\n",
        "\n",
        "print('>> Number of duplications found: ', count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eit1NBpieTBT"
      },
      "source": [
        "As from above, we found 3 duplications. Let's plot those duplications for detailed exploration. If they are the same, we can keep one and eliminate other. However, since we use hashlib's md5() method to compute the hash of the image, it is likely that 2 different inputs can be resulted in the same hash value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSdGbQbHoJFY"
      },
      "outputs": [],
      "source": [
        "# plot the duplicate images side by side\n",
        "for i in range(0, len(duplicates), 2):\n",
        "    filename1 = duplicates[i]\n",
        "    filepath1 = os.path.join(image_dir, filename1)\n",
        "    image1 = Image.open(filepath1)\n",
        "    \n",
        "    if i+1 < len(duplicates):\n",
        "        filename2 = duplicates[i+1]\n",
        "        filepath2 = os.path.join(image_dir, filename2)\n",
        "        image2 = Image.open(filepath2)\n",
        "        \n",
        "        # plot the images side by side\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
        "        axs[0].imshow(image1)\n",
        "        axs[0].set_title(filename1)\n",
        "        axs[0].axis('off')\n",
        "        axs[1].imshow(image2)\n",
        "        axs[1].set_title(filename2)\n",
        "        axs[1].axis('off')\n",
        "        plt.show()\n",
        "    else:\n",
        "        fig, axs = plt.subplots(1, 1, figsize=(3, 3))\n",
        "        axs.imshow(image1)\n",
        "        axs.set_title(filename1)\n",
        "        axs.axis('off')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TxJinRDimdC"
      },
      "source": [
        "After checking, we can be sure that there are 3 duplications in our dataset images patch. Based on the finding, we will remove the duplicate imnage from the dataset.\n",
        "\n",
        "It is important to handling duplicate images, since it will help us to avoid any bias when training the model and avoid failing to generalie new data [(Lee, 2021)](https://medium.com/mlearning-ai/a-scalable-solution-to-detect-duplicate-images-97d431c2726d)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OQtMITjknRD"
      },
      "outputs": [],
      "source": [
        "# Create a list to store unique images\n",
        "unique_images = []\n",
        "\n",
        "# Create a set to store unique hash values\n",
        "unique_hashes = set()\n",
        "\n",
        "# Iterate over each image in the directory\n",
        "for filename in os.listdir(image_dir):\n",
        "    # Calculate the hash value of the image\n",
        "    with open(os.path.join(image_dir, filename), 'rb') as f:\n",
        "        image_hash = hashlib.md5(f.read()).hexdigest()\n",
        "    \n",
        "    # Check if the hash value is already in the list of unique hashes\n",
        "    if image_hash not in unique_hashes:\n",
        "        # Add the image to the list of unique images\n",
        "        unique_images.append(filename)\n",
        "        # Add the hash value to the set of unique hashes\n",
        "        unique_hashes.add(image_hash)\n",
        "    else:\n",
        "        # Delete the duplicate image from the directory\n",
        "        os.remove(os.path.join(image_dir, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42ho-0pIt3yA"
      },
      "source": [
        "## 3. Preprocessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsmQgX9oyMZg"
      },
      "source": [
        "### Handle Imbalanced Dataset\n",
        "\n",
        "As explored in the EDA above, we have an imbalanced dataset for the classes: cancerous and non-cancerous cells (isCancerous or not). To tackle this problem, we can try to resample our data.\n",
        "\n",
        "For this project, since the size of the dataset is not too large, we will not perform undersampling. Instead of that, we can upsample our dataset by adding random duplicate data from the minor class. However, this technique can have one drawback which is causing overfitting to our model. \n",
        "\n",
        "To this point, we can think of the extra dataset and use it to add more data for our minor class and make it balanced with the major class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcsyxWdp9Qva"
      },
      "outputs": [],
      "source": [
        "print(\"Before balancing the dataset\")\n",
        "isCancerous_count = data.isCancerous.value_counts()\n",
        "print(isCancerous_count)\n",
        "print('-------------------------------')\n",
        "# Balance the dataset\n",
        "# Calculate the gap between 2 classes\n",
        "gap = isCancerous_count[0] - isCancerous_count[1]\n",
        "# Take data from the extra dataset\n",
        "extra_data_isCancerous = data_extra[data_extra['isCancerous'] == 1].sample(gap)\n",
        "# Concat the two\n",
        "data = pd.concat([data, extra_data_isCancerous], ignore_index=True)\n",
        "\n",
        "print(\"After balancing the dataset\")\n",
        "data.isCancerous.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbqYukYu7o1-"
      },
      "source": [
        "### Get data for Task 1\n",
        "\n",
        "For Task 1, which is checking if a cell is cancerous or not, therefore, we only need to keep relevant attributes such as: isCancerous, ImageName"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEEGjyOT8J49"
      },
      "outputs": [],
      "source": [
        "# cancerous_data for Task 1\n",
        "cancerous_data = data[['ImageName', 'isCancerous']]\n",
        "cancerous_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAiiCRUlyn0b"
      },
      "source": [
        "### Data Splitting\n",
        "Randomly splitting data into train, test, and validation set with the proportion of 60 - 20 - 20 respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukbZyHa82u02"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(cancerous_data, test_size=0.2, random_state=107)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=107)\n",
        "\n",
        "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(train_data.shape[0], val_data.shape[0], test_data.shape[0]))\n",
        "\n",
        "# Ref: http://localhost:8888/notebooks/rmit_cosc_2673_2793-2310/labs/week08/Week08_lab_excercises_NN.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLcP-cB-1T0n"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7Nwd3EZ0WhZ"
      },
      "source": [
        "### Data Normalization and Data Augmentation\n",
        "We will use 'ImageDataGenerator' from 'keras.preprocessing.image' to apply augmentation to our data. The function will horizontally flip the photos, adjust their height and width, and rotate them at random. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hewFw7mye6t"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def dataframe_generator(data_fr, x_column=\"ImageName\", y_column=\"cellTypeName\", classes=[\"epithelial\", \"fibroblast\", \"inflammatory\", \"others\"]):\n",
        "  # Convert the label to string format\n",
        "  data_fr[y_column] = data_fr[y_column].astype('str')\n",
        "\n",
        "  # Init default params\n",
        "  batch_size = 64\n",
        "  img_size = (27, 27)\n",
        "\n",
        "  # Define data generators for preprocessing and data augmentation\n",
        "  data_gen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      validation_split=0.2)\n",
        "\n",
        "  data_generator = data_gen.flow_from_dataframe(\n",
        "          dataframe=data_fr,\n",
        "          directory='/dataset/patch_images',\n",
        "          x_col=x_column,\n",
        "          y_col=y_column,\n",
        "          batch_size=batch_size,\n",
        "          target_size=img_size,\n",
        "          class_mode='categorical',\n",
        "          classes=classes)\n",
        "  return data_generator\n",
        "\n",
        "# Ref1: https://viblo.asia/p/tang-cuong-du-lieu-trong-deep-learning-oOVlYe4nl8W\n",
        "# Ref2: http://localhost:8888/notebooks/rmit_cosc_2673_2793-2310/labs/week09/Week9_lab_exercises.ipynb\n",
        "# Ref3: https://www.datacamp.com/tutorial/complete-guide-data-augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0aR8gNPGDH8"
      },
      "outputs": [],
      "source": [
        "# Apply datagenerator to train, test, and validation set\n",
        "train_data_gen = dataframe_generator(train_data, y_column='isCancerous', classes=['0', '1'])\n",
        "test_data_gen = dataframe_generator(test_data, y_column='isCancerous', classes=['0', '1'])\n",
        "val_data_gen = dataframe_generator(val_data, y_column='isCancerous', classes=['0', '1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGfiQh0b6LV8"
      },
      "source": [
        "## Model Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScuspBtCGeY5"
      },
      "source": [
        "### 1. Determine your goals\n",
        "* Performance metric\n",
        "* Target value\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KNfGZQfHhYo"
      },
      "source": [
        "### 2. Setup the experiment: \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGNAlJEq6cQe"
      },
      "source": [
        "\n",
        "\n",
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvTH5pGgokqA"
      },
      "outputs": [],
      "source": [
        "# Performance Metrics\n",
        "from keras import backend as K\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlRD4bxq-H10"
      },
      "source": [
        "**Set up functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV1il56WIJQ3"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curve(train_loss, val_loss, train_metric, val_metric, metric_name='Accuracy'):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    \n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(train_loss, 'r--')\n",
        "    plt.plot(val_loss, 'b--')\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(train_metric, 'r--')\n",
        "    plt.plot(val_metric, 'b--')\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Ref: http://localhost:8888/notebooks/rmit_cosc_2673_2793-2310/labs/week09/Week9_lab_exercises.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPcdOyIJ68FV"
      },
      "source": [
        "**Performance Metrics:** set up functions for evaluation. In this project, since we have balanced our dataset, we will use the accuracy metric, together with other metrics such as: precision, recall, and f1 to evaluate the models performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VASIA1iHnmtL"
      },
      "outputs": [],
      "source": [
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall_keras\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision_keras\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
        "\n",
        "# List of the metrics\n",
        "METRICS = ['accuracy', recall, precision, f1]\n",
        "\n",
        "# Ref: https://gist.github.com/arnaldog12/5f2728f229a8bd3b4673b72786913252"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhcItFDa6Okv"
      },
      "source": [
        "### Base Model - Neural Networks (MLP)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC-rUggB-PvT"
      },
      "source": [
        "1. Overview\n",
        "2. Setup\n",
        "3. Preprocessing\n",
        "4. Modeling (compile & train)\n",
        "5. Incremental change\n",
        "6. Evaluate the final model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4RxRjO2IPOH"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = (27,27,3)\n",
        "HIDDEN_LAYER_DIM = 256\n",
        "OUTPUT_CLASSES = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI5RF1E6ISs6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the model architecture\n",
        "model_NN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=INPUT_DIM),\n",
        "    tf.keras.layers.Dense(HIDDEN_LAYER_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI5iYiVRJ2Lc"
      },
      "outputs": [],
      "source": [
        "model_NN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAj4phFMJ5qP"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model_NN, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7O3_1rMKAwL"
      },
      "outputs": [],
      "source": [
        "model_NN.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TSQDkE9KMkq"
      },
      "outputs": [],
      "source": [
        "history = model_NN.fit(train_data_gen, validation_data = val_data_gen, epochs=50, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B3zY8cZKQl8"
      },
      "outputs": [],
      "source": [
        "plot_learning_curve(history.history['loss'], history.history['val_loss'], \n",
        "                    history.history['accuracy'], history.history['val_accuracy'], \n",
        "                    metric_name='Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lji2-R36_L4p"
      },
      "outputs": [],
      "source": [
        "model_NN.evaluate(train_data_gen)\n",
        "model_NN.evaluate(val_data_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N4iVZenAtex"
      },
      "source": [
        "The validation set score seems to be slightly smaller than the train set score, which indicates our model is a little bit overfit. We can apply some techniques to handle this problem such as: Drop out, or Do some regularization. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ellGnXZqF-Rk"
      },
      "outputs": [],
      "source": [
        "model_NN_drop = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=INPUT_DIM),\n",
        "    tf.keras.layers.Dense(HIDDEN_LAYER_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(.3),\n",
        "    tf.keras.layers.Dense(OUTPUT_CLASSES)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WX_PHOmG5_0"
      },
      "outputs": [],
      "source": [
        "model_NN_drop.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWd-EH-3G7tr"
      },
      "outputs": [],
      "source": [
        "history_drop = model_NN_drop.fit(train_data_gen, validation_data = val_data_gen, epochs=50, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14zjgWJuGY6F"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history_drop.history['loss'], 'r--')\n",
        "plt.plot(history_drop.history['val_loss'], 'b--')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history_drop.history['accuracy'], 'r--')\n",
        "plt.plot(history_drop.history['val_accuracy'], 'b--')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC2Z1g8kKmLD"
      },
      "outputs": [],
      "source": [
        "model_NN_drop.evaluate(train_data_gen)\n",
        "model_NN_drop.evaluate(val_data_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVFqevJcKtJU"
      },
      "source": [
        "After applying \"drop out\", our model seems to be badly underfit. Therefore, we can adjust the value of drop out and add extra layer to see if we can improve the model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boX0NvaA_U2h"
      },
      "source": [
        "Add 1 extra layer + modified drop out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0XtV6wy_WDF"
      },
      "outputs": [],
      "source": [
        "# Define the 'model with 1 extra layer' architecture\n",
        "model_NN_1_drop = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=INPUT_DIM),\n",
        "    tf.keras.layers.Dense(HIDDEN_LAYER_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(.5),\n",
        "    tf.keras.layers.Dense(HIDDEN_LAYER_DIM*(1/3), activation='relu'),\n",
        "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Check model architecture\n",
        "model_NN_1_drop.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UH3-sugqF2n"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model_NN_1_drop, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIIRVLlxI8rR"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model_NN_1_drop.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbVhWUj8IaOr"
      },
      "outputs": [],
      "source": [
        "# Fit with the train and val dataset\n",
        "history_NN_1_drop = model_NN_1_drop.fit(train_data_gen, validation_data=val_data_gen, epochs=50, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3FxlklLpl04"
      },
      "outputs": [],
      "source": [
        "plot_learning_curve(history_NN_1_drop.history['loss'], history_NN_1_drop.history['val_loss'], \n",
        "                    history_NN_1_drop.history['accuracy'], history_NN_1_drop.history['val_accuracy'], \n",
        "                    metric_name='Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn_GxNG-IcBr"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "model_NN_1_drop.evaluate(train_data_gen)\n",
        "model_NN_1_drop.evaluate(val_data_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsm81JZsJpTs"
      },
      "source": [
        "We can see that after adjusting the drop out value and add more extra layer with the aim to make our model more generalized, however, the model seems to perform badly (accuracy only 50% on both train set and validation set) compared to the default neural networks (84% on train set and 83% on validation set). Therefore, we may keep the default neural networks as our final NN model and then evaluate it on the test set. Next, we can think of building other models to see if it can perform better than the NN one. We can use the evaluation scores we get on the test set to compare those models together. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXwe2ZRsrC3n"
      },
      "source": [
        "#### Evaluation\n",
        "\n",
        "Testing the final version of neural networks model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZL6h6vIvv-w"
      },
      "source": [
        "We now have the final version of neural nertworks. We then use the test dataset to evaluate this model once again and save it for further comparison with other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXcQmfGUrFEB"
      },
      "outputs": [],
      "source": [
        "# Task 1: Neural Networks Evaluation\n",
        "t1_nn_evaluation = model_NN.evaluate(test_data_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg7391hJazr3"
      },
      "outputs": [],
      "source": [
        "Y_pred = model_NN.predict(train_data_gen)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print(classification_report(train_data_gen.classes, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Q51uZDHKSe"
      },
      "source": [
        "### Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDlEZwbHHYnx"
      },
      "source": [
        "### ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ref: https://medium.com/analytics-vidhya/understanding-and-implementation-of-residual-networks-resnets-b80f9a507b9c\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    \n",
        "    return X"
      ],
      "metadata": {
        "id": "CGSpZeDpNAqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ref: https://medium.com/analytics-vidhya/understanding-and-implementation-of-residual-networks-resnets-b80f9a507b9c\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "\n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f,f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer=glorot_uniform(seed =0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu') (X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1,1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer=glorot_uniform(seed =0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1,1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer=glorot_uniform(seed =0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    \n",
        "    return X"
      ],
      "metadata": {
        "id": "oK2i5FuFNLsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ref: https://medium.com/analytics-vidhya/understanding-and-implementation-of-residual-networks-resnets-b80f9a507b9c\n",
        "\n",
        "def ResNet50(input_shape = (27, 27, 3), classes = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = initializers.RandomNormal(stddev=0.01))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    X = ZeroPadding2D((1, 1))(X_input)\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='d')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='e')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='f')\n",
        "\n",
        "    # Stage 6\n",
        "    X = convolutional_block(X, f = 3, filters = [1024, 1024, 2048], stage = 6, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [1024, 1024, 2048], stage=6, block='b')\n",
        "    X = identity_block(X, 3, [1024, 1024, 2048], stage=6, block='c')\n",
        "    \n",
        "    # AVGPOOL . Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = MaxPooling2D()(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = GlorotUniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9--ltwWeNcPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1_model_resnet50 = ResNet50()\n",
        "t1_model_resnet50.summary()\n",
        "\n",
        "# Model Architecture\n",
        "plot_model(t1_model_resnet50, show_shapes=True)"
      ],
      "metadata": {
        "id": "Lx4X3iO5QMJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "# Set up optimizer\n",
        "optimizerr = Adam(lr = 0.0045, amsgrad=True) # set learning rate\n",
        "\n",
        "# Fit model\n",
        "history_t1_model_resnet50 = fit_model(t1_model_resnet50, train_data_gen, val_data_gen, name=\"Task1_Resnet50\")"
      ],
      "metadata": {
        "id": "Cw81ljgpQm_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_t1_model_resnet50 = t1_model_resnet50.evaluate(test_data_gen)"
      ],
      "metadata": {
        "id": "m8Xyny0GRSI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_caN3DuHlN6"
      },
      "source": [
        "### GoogLeNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0LBNdFHx-O"
      },
      "source": [
        "### AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x52uqHYewaDe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aD86sQAKiK5"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tRGJTkZHzaC"
      },
      "source": [
        "# Task II: Cell-type Classification\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}